{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ac76d77-77af-4d03-aff6-1b2cb6774553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50540it [00:59, 845.56it/s] \n",
      "2661it [00:03, 719.09it/s]\n",
      "25670it [00:34, 734.99it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import seaborn as sns\n",
    "\n",
    "BASE_DIR = r\"C:\\Users\\Keelan.Butler\\Desktop\\python_projects\\Final Project\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "ROUTE_DIR = r\"C:\\Users\\Keelan.Butler\\Desktop\\python_projects\\Final Project\"\n",
    "DATA_DIR = os.path.join(ROUTE_DIR,\"Sentry-AI\",\"Python\")\n",
    "FEATURE_PATH = os.path.join(BASE_DIR,\"Dataset\",\"features\")\n",
    "os.chdir(DATA_DIR)\n",
    "df_train, df_test = pd.read_csv('Train_set.csv'),pd.read_csv('Test_set.csv')\n",
    "# load features \n",
    "df_train_new, df_val = train_test_split(df_train, test_size=0.05, stratify=df_train['Anomaly_Type'], random_state=42)\n",
    "\n",
    "def load_features(dataframe):\n",
    "    \"\"\"Function extracts features from dataframe and processes them for modelling.\n",
    "    returns: features, anomaly, anomaly_bool, frame_number\n",
    "    Arg:\n",
    "    - dataframe: This will be our test/train dataset. \n",
    "    Returns: \n",
    "    - Features: Loaded features from corresponding npy file. \n",
    "    - anon_type: A break down on what anomaly has occured, otherwise Normal. \n",
    "    - anon_bool: A boolean of anomaly occurance.\n",
    "    - start_frame: List of the corresponding final frame of the sliding window\n",
    "    - end_frame: List of the corresponding final frame of the sliding window\n",
    "    - video_names: List of video names, this enables up to partition by videos.\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    anon_type = []\n",
    "    anon_bool = []\n",
    "    start_index = []\n",
    "    end_index = []\n",
    "    video_names = []\n",
    "    for path,subdir, label, lab_bool, clip_start, clip_end, video_name in tqdm(zip(dataframe['feature_path'],dataframe['subfolder'], dataframe['Anomaly_Type'], dataframe['Anomaly'], dataframe['Start_of_Clip'], dataframe['End_of_Clip'], dataframe['name'])):\n",
    "        feature = np.load(os.path.join(FEATURE_PATH,subdir,path)) # Accesses the relevant path through our relational database \n",
    "        features.append(feature) # List of loaded npy features.\n",
    "        anon_type.append(label) # List of type of anomalies. \n",
    "        anon_bool.append(lab_bool) # 1 for anomaly, 0 for normal.\n",
    "        video_names.append(video_name) # List of video names.\n",
    "        start_index.append(clip_start) # List of clip start frame\n",
    "        end_index.append(clip_end) # List of clip start frame\n",
    "    return features, anon_type, anon_bool, start_index,end_index, video_names\n",
    "\n",
    "train_features, train_anon_type, train_anon_bool, train_start_index,train_end_index, train_video_names = load_features(df_train_new)\n",
    "val_features, val_anon_type, val_anon_bool, val_start_index,val_end_index, val_video_names = load_features(df_val)\n",
    "test_features, test_anon_type, test_anon_bool, test_start_index, test_end_index, test_video_names = load_features(df_test)\n",
    "\n",
    "l_encoder = LabelEncoder()\n",
    "train_anon_type = l_encoder.fit_transform(train_anon_type)\n",
    "val_anon_type = l_encoder.transform(val_anon_type)\n",
    "test_anon_type = l_encoder.transform(test_anon_type)\n",
    "\n",
    "class CLIP_DATA(Dataset):\n",
    "    \"\"\"Dataset class for clip-based video anomaly detection\"\"\"\n",
    "\n",
    "    def __init__(self, features, anon_label, anon_bool):\n",
    "        self.features = [torch.from_numpy(arr).float() for arr in features]  # Convert once\n",
    "        self.anon_label = torch.tensor(anon_label, dtype=torch.long)  # Label-encoded anomaly type\n",
    "        self.anon_bool = torch.tensor(anon_bool, dtype=torch.float32)  # Binary anomaly indicator (0 or 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features) \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.anon_label[idx], self.anon_bool[idx]\n",
    "\n",
    "\n",
    "training_data = CLIP_DATA(train_features, train_anon_type, train_anon_bool)\n",
    "validation_data = CLIP_DATA(val_features, val_anon_type, val_anon_bool)\n",
    "test_data = CLIP_DATA(test_features, test_anon_type, test_anon_bool)\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=False)\n",
    "validation_dataloader = DataLoader(training_data, batch_size=64, shuffle=False)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcd8043-c5b4-41e9-8d10-41f9adbe34a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "model.fit(train_features, train_anon_bool)\n",
    "\n",
    "\n",
    "print(\"Initial Model Accuracy:\", model.score(test_features, test_anon_bool))\n",
    "print(\"Initial Model F1 Score:\", metrics.f1_score(test_anon_bool, model.predict(test_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ad209d-fe06-4e8f-ac83-30ab77e072bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_cm = metrics.confusion_matrix(test_anon_bool, model.predict(test_features))\n",
    "sns.heatmap(original_cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e635bba8-0021-4f2c-9255-cd783a7ce553",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.f1_score(model.predict(test_features),test_anon_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718bf7db-3fc4-42ce-93a7-5ddf21ee8c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 300, 500, 1000],  # Number of trees\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2]  # Step size shrinkage\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e0fdb7-c5c4-44d4-8ebc-6c18b6ff2008",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GridSearchCV(model, param_grid=param_grid, cv=3, scoring=\"f1\")\n",
    "search.fit(val_features, val_anon_bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8ad27f-2f27-496f-9ece-be4b6fc5af9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvgs_results = pd.DataFrame(search.cv_results_)\n",
    "print(cvgs_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db36869-2a45-4bed-9684-c3e40c22682c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_optimised = GradientBoostingClassifier(**search.best_params_)\n",
    "model_optimised.fit(train_features, train_anon_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2d4483-6aae-4953-b085-ffa9cdb81fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimized Model Accuracy:\", model_optimised.score(test_features, test_anon_bool))\n",
    "print(\"Optimized Model F1 Score:\", metrics.f1_score(test_anon_bool, model_optimised.predict(test_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265ca329-6a0f-45bc-a559-429b3361b78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimised_cm = metrics.confusion_matrix(test_anon_bool, model_optimised.predict(test_features))\n",
    "sns.heatmap(optimised_cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20be422-bc12-4d40-998a-3a9388a9f48f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
