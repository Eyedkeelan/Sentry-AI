{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea6ac8b6-0d59-458e-8a27-8998021bc1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# END2END RESNET \n",
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "800919cf-1114-498f-97af-cb141b5e8e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_INTERVAL = 5  # Capture every 5th frame\n",
    "CLIP_LENGTH = 16  # Number of frames per clip for 3D CNN\n",
    "FRAME_HEIGHT, FRAME_WIDTH = 224, 224  # r3d_18 with input 112x112 Slowfast 224x224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ded568fa-5734-4df6-8b88-568bfd87abde",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_DIR = r\"C:\\Users\\Keelan.Butler\\Desktop\\python_projects\\Final Project\\OneDrive_2025-01-30\\MSAD Dataset\\MSAD_blur\"\n",
    "SAVE_DIR = r\"C:\\Users\\Keelan.Butler\\Desktop\\python_projects\\Final Project\\Processed_Frames\"\n",
    "Anomaly_dir = r\"C:\\Users\\Keelan.Butler\\Desktop\\python_projects\\Final Project\\OneDrive_2025-01-30\\MSAD Dataset\\anomaly_annotation.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2dc273bb-4e46-46ed-aced-3a5ce30187be",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((FRAME_HEIGHT, FRAME_WIDTH)), \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalising the features\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d85cdf18-899d-4bad-a756-6f9c9c022b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomalies: {'Fighting', 'Water', 'Traffic', 'Vandalism', 'Object', 'Explosion', 'Assault', 'Fire', 'Shooting', 'People', 'Robbery'}\n"
     ]
    }
   ],
   "source": [
    "Anomaly_data = pd.read_csv(Anomaly_dir)\n",
    "anomalies = set([anon.split(\"_\")[0] for anon in Anomaly_data.name.values])\n",
    "print(f'Anomalies: {anomalies}')\n",
    "\n",
    "anno_names = Anomaly_data.name.values.tolist()\n",
    "anno_start = Anomaly_data['starting frame of anomaly'].values.tolist()\n",
    "anno_end = Anomaly_data['ending frame of anomaly'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca535937-6d07-43e0-ab25-9cd93b8fe012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save directory for extracted frames\n",
    "\n",
    "def extract_and_save_frames(video_path, save_dir, frame_interval=5):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    save_folder = os.path.join(save_dir, video_name)\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "    frame_count = 0\n",
    "    saved_count = 0\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break  # End of video\n",
    "\n",
    "        if frame_count % frame_interval == 0:\n",
    "            # Convert BGR (OpenCV) to RGB (PIL)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Apply transformations\n",
    "            frame = transform(frame)  # Now it's a Tensor (C, H, W)\n",
    "\n",
    "            # Convert back to PIL image to save\n",
    "            frame = transforms.ToPILImage()(frame)\n",
    "\n",
    "            # Save frame as JPEG\n",
    "            frame_path = os.path.join(save_folder, f\"frame_{saved_count:04d}.jpg\")\n",
    "            frame.save(frame_path, \"JPEG\")\n",
    "            saved_count += 1 \n",
    "\n",
    "        frame_count += 1\n",
    "    \n",
    "    cap.release()\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2169e237-6fe1-4d1c-a871-d31e7f19942d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Frames C:\\Users\\Keelan.Butler\\Desktop\\python_projects\\Final Project\\OneDrive_2025-01-30\\MSAD Dataset\\MSAD_blur: 0it [00:00, ?it/s]\n",
      "Extracting Frames C:\\Users\\Keelan.Butler\\Desktop\\python_projects\\Final Project\\OneDrive_2025-01-30\\MSAD Dataset\\MSAD_blur\\MSAD_anomaly_blur: 0it [00:00, ?it/s]\n",
      "Extracting Frames C:\\Users\\Keelan.Butler\\Desktop\\python_projects\\Final Project\\OneDrive_2025-01-30\\MSAD Dataset\\MSAD_blur\\MSAD_anomaly_blur\\Ass\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'label' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m video_file\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.avi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.mov\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m      4\u001b[0m     video_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root, video_file)\n\u001b[1;32m----> 5\u001b[0m     anon_label \u001b[38;5;241m=\u001b[39m \u001b[43mextract_and_save_frames\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSAVE_DIR\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[24], line 35\u001b[0m, in \u001b[0;36mextract_and_save_frames\u001b[1;34m(video_path, save_dir, frame_interval)\u001b[0m\n\u001b[0;32m     32\u001b[0m     frame_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     34\u001b[0m cap\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlabel\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'label' is not defined"
     ]
    }
   ],
   "source": [
    "for root, _, files in os.walk(VIDEO_DIR):\n",
    "    for video_file in tqdm(files, desc=f\"Extracting Frames {root}\"):\n",
    "        if video_file.endswith((\".mp4\", \".avi\", \".mov\")):\n",
    "            video_path = os.path.join(root, video_file)\n",
    "            anon_label = extract_and_save_frames(video_path, SAVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba43863d-f98f-41b3-9191-93a4d40a7024",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly = []\n",
    "anonamly_bool = []\n",
    "frame_paths = []\n",
    "frames = []\n",
    "video_names = []\n",
    "video_path = []\n",
    "import os\n",
    "for root, _, files in os.walk(SAVE_DIR):\n",
    "   for name in files:\n",
    "      frame_path = os.path.join(root, name)\n",
    "      components = frame_path.split(os.sep) \n",
    "      video_name =  components[-2]\n",
    "      frame = int(components[-1].split(\"_\")[1].split(\".\")[0]) * FRAME_INTERVAL\n",
    "      frames.append(frame)\n",
    "      video_names.append(video_name)\n",
    "      #print(video_name) \n",
    "      frame_paths.append(frame_path)\n",
    "      anom = video_name.split(\"_\")[0]\n",
    "      if anom in anomalies:\n",
    "          #print(frame,video_name)\n",
    "          pos = anno_names.index(video_name)\n",
    "          start = anno_start[pos]\n",
    "          end = anno_end[pos]\n",
    "\n",
    "          if start < frame < end: \n",
    "              anon_bool = 1 \n",
    "              anomaly_label = anom\n",
    "          else:\n",
    "              anon_bool = 0\n",
    "              anomaly_label = \"Normal\"\n",
    "         \n",
    "      else:\n",
    "          anon_bool = 0\n",
    "          anomaly_label = \"Normal\"\n",
    "      anomaly.append(anomaly_label)\n",
    "      anonamly_bool.append(anon_bool)\n",
    "\n",
    "\n",
    "metadata = pd.DataFrame({'Video':video_names,\n",
    "              'Frame':frames,\n",
    "             'Frames_path':frame_paths, \n",
    "             \"Anomaly Type\": anomaly,\n",
    "             \"Anomaly\": anonamly_bool})\n",
    "\n",
    "metadata[\"Video\"] = metadata[\"Video\"].str.replace(\"MSAD_normal_\", \"\", regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48eb94a2-700f-4aac-87ed-3c5d69a44b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\Keelan.Butler\\Desktop\\python_projects\\Final Project\\OneDrive_2025-01-30\\MSAD Dataset\\MSAD_I3D_WS_Train.list') as train:\n",
    "    t = train.readlines()\n",
    "    train_list = [item.split(\"\\n\")[0].split(\"/\")[-1].replace(\"_i3d.npy\",\"\") for item in t]\n",
    "    train_label = [\"Train\"] * len(train_list)\n",
    "tr_labels = pd.DataFrame({\"Video\":train_list,\n",
    "                        \"partition\":train_label}) \n",
    "with open(r'C:\\Users\\Keelan.Butler\\Desktop\\python_projects\\Final Project\\OneDrive_2025-01-30\\MSAD Dataset\\MSAD_I3D_WS_Test.list') as test:\n",
    "    t = test.readlines()\n",
    "    test_list = [item.split(\"\\n\")[0].split(\"/\")[-1].replace(\"_i3d.npy\",\"\") for item in t]\n",
    "    test_label = [\"Test\"] * len(test_list)\n",
    "\n",
    "te_labels = pd.DataFrame({\"Video\":test_list,\n",
    "                         \"partition\":test_label})\n",
    "label_df = pd.concat([tr_labels,te_labels])\n",
    "label_df[\"Video\"] = label_df[\"Video\"].str.replace(\"MSAD_normal_\", \"\", regex=False)\n",
    "label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5a2775-0653-49ae-a88e-c55f21710afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(left= metadata, right = label_df , on= \"Video\",how= \"left\")\n",
    "df_train =  df[df[\"partition\"] == \"Train\"].drop(columns= \"partition\")\n",
    "df_test =  df[df[\"partition\"] == \"Test\"].drop(columns= \"partition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c769c60d-6815-4813-8392-0964c155bff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrameDataset(Dataset):\n",
    "    def __init__(self, labels_df, transform=None, clip_length=32, tau=4, step_size=8):\n",
    "        \"\"\"\n",
    "        labels_df: DataFrame with columns [\"Video\", \"Frame\", \"Frames_path\", \"Anomaly Type\", \"Anomaly\"]\n",
    "        transform: Image transformations (for resizing, normalizing, etc.)\n",
    "        clip_length: Number of frames per sample for Fast Path (default 32)\n",
    "        tau: Frame stride for Slow Path (default 4, meaning every 4th frame)\n",
    "        step_size: How far the window moves per sample (default 8)\n",
    "        \"\"\"\n",
    "        self.labels_df = labels_df.copy()  # Prevent modifying the original DataFrame\n",
    "        self.transform = transform\n",
    "        self.clip_length = clip_length\n",
    "        self.tau = tau\n",
    "        self.step_size = step_size\n",
    "\n",
    "        # Ensure data is sorted by video and frame number\n",
    "        self.labels_df.sort_values(by=[\"Video\", \"Frame\"], inplace=True)\n",
    "\n",
    "        # Group frames by video\n",
    "        self.video_groups = self.labels_df.groupby(\"Video\")\n",
    "\n",
    "        # Encode labels\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.labels_df[\"Encoded_Label\"] = self.label_encoder.fit_transform(self.labels_df[\"Anomaly\"])\n",
    "\n",
    "        # Store unique videos\n",
    "        self.video_list = list(self.video_groups.groups.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        total_clips = 0\n",
    "        for video_name in self.video_list:\n",
    "            num_frames = len(self.video_groups.get_group(video_name))\n",
    "            num_clips = max(0, (num_frames - self.clip_length) // self.step_size + 1)\n",
    "            total_clips += num_clips\n",
    "        return total_clips\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Determine video & clip index\n",
    "        total_clips = 0\n",
    "        for video_name in self.video_list:\n",
    "            video_frames = self.video_groups.get_group(video_name)\n",
    "            num_frames = len(video_frames)\n",
    "            num_clips = max(0, (num_frames - self.clip_length) // self.step_size + 1)\n",
    "\n",
    "            if idx < total_clips + num_clips:\n",
    "                clip_idx = idx - total_clips\n",
    "                break\n",
    "\n",
    "            total_clips += num_clips\n",
    "        else:\n",
    "            raise IndexError(f\"Index {idx} is out of range for dataset of length {self.__len__()}\")\n",
    "\n",
    "        # Get frames & labels\n",
    "        frame_paths = video_frames[\"Frames_path\"].tolist()\n",
    "        frame_labels = video_frames[\"Encoded_Label\"].tolist()\n",
    "\n",
    "        start_idx = clip_idx * self.step_size\n",
    "\n",
    "        # Select frames for **Fast Path**\n",
    "        fast_frames_paths = frame_paths[start_idx:start_idx + self.clip_length]\n",
    "        fast_labels = frame_labels[start_idx:start_idx + self.clip_length]\n",
    "\n",
    "        # Select frames for **Slow Path** (every `tau` frames from fast frames)\n",
    "        slow_frames_paths = fast_frames_paths[::self.tau]\n",
    "        slow_labels = fast_labels[::self.tau]\n",
    "\n",
    "        # Ensure Slow Path has enough frames\n",
    "        while len(slow_frames_paths) < self.clip_length // self.tau:\n",
    "            slow_frames_paths.append(slow_frames_paths[-1])\n",
    "            slow_labels.append(slow_labels[-1])\n",
    "\n",
    "        # Load images\n",
    "        def load_frames(paths):\n",
    "            frames = []\n",
    "            for frame_path in paths:\n",
    "                frame = cv2.imread(frame_path)\n",
    "                if frame is None:\n",
    "                    raise ValueError(f\"Error reading image: {frame_path}\")\n",
    "\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                if self.transform:\n",
    "                    frame = self.transform(frame)\n",
    "                else:\n",
    "                    frame = torch.from_numpy(frame).float()\n",
    "\n",
    "                frames.append(frame)\n",
    "\n",
    "            return torch.stack(frames)  # Shape: (T, C, H, W)\n",
    "\n",
    "        fast_frames = load_frames(fast_frames_paths)\n",
    "        slow_frames = load_frames(slow_frames_paths)\n",
    "\n",
    "        # Transpose to match SlowFast input format (C, T, H, W)\n",
    "        fast_frames = fast_frames.permute(1, 0, 2, 3)  # (C, T, H, W)\n",
    "        slow_frames = slow_frames.permute(1, 0, 2, 3)  # (C, T/4, H, W)\n",
    "\n",
    "        # Assign majority label\n",
    "        clip_label = torch.tensor(fast_labels).mode()[0]  # Get most frequent label\n",
    "\n",
    "        return [slow_frames, fast_frames], torch.tensor(clip_label, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8df11e-c93e-4c13-a027-8183d192bb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = FrameDataset(labels_df = df_train)\n",
    "testing_dataset = FrameDataset(labels_df = df_test)\n",
    "print(\"Training dataset size: {}\\ntesting dataset size: {}\".format(len(training_dataset),len(testing_dataset)))\n",
    "num_workers = min(6, os.cpu_count() - 1)\n",
    "training_dataloader = torch.utils.data.DataLoader(training_dataset, batch_size=16, shuffle=False, num_workers=0)##, pin_memory=True)\n",
    "testing_dataloader = torch.utils.data.DataLoader(testing_dataset, batch_size=16, shuffle=False, num_workers=0)#, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e89f7af-bd0f-4fbc-931a-7ff68e850f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "slowfast_model = torch.hub.load('facebookresearch/pytorchvideo', 'slowfast_r50', pretrained=True)\n",
    "\n",
    "# Remove classification head\n",
    "slowfast_model.blocks[-1] = nn.Identity() # Remove the final classification layer\n",
    "\n",
    "class SlowFastBinaryClassifier(nn.Module):\n",
    "    def __init__(self, slowfast_model):\n",
    "        super(SlowFastBinaryClassifier, self).__init__()\n",
    "        self.slowfast_model = slowfast_model\n",
    "        self.fc = nn.Linear(2304 , 1)  # Output 1 for binary classification\n",
    "\n",
    "    def forward(self, slow_frames, fast_frames):\n",
    "        features = self.slowfast_model([slow_frames, fast_frames])  # Forward pass\n",
    "        print(\"Feature shape before pooling:\", features.shape)\n",
    "        \n",
    "        features = F.adaptive_avg_pool3d(features, (1, 1, 1)).squeeze()\n",
    "\n",
    "        return self.fc(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf5245b-6182-49cc-8bec-e3d18b6e1acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_binary = SlowFastBinaryClassifier(slowfast_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92ffa91-af57-42c7-82c8-d1fc24fe6f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Hyperparameters\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_binary = SlowFastBinaryClassifier(slowfast_model)\n",
    "\n",
    "epochs = 25\n",
    "losses = np.zeros((2, epochs))\n",
    "model_binary.to(device)\n",
    "\n",
    "optimiser = optim.Adam(model_binary.parameters(), lr=1e-4, weight_decay=1e-4)  \n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Use GPU if available\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "best_loss = np.inf\n",
    "\n",
    "threshhold = 0.5 \n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0.0\n",
    "    model_binary.train()\n",
    "\n",
    "    for frames, labels in tqdm(training_dataloader, desc=\"Training pass\"):\n",
    "        torch.cuda.empty_cache()  \n",
    "        slow_frames, fast_frames = frames  # Unpack SlowFast inputs\n",
    "        \n",
    "        slow_frames, fast_frames, labels = (\n",
    "            slow_frames.to(device),\n",
    "            fast_frames.to(device),\n",
    "            labels.to(device),\n",
    "        )\n",
    "\n",
    "        slow_frames = slow_frames.permute(0, 4, 2, 3, 1)\n",
    "        fast_frames = fast_frames.permute(0, 4, 2, 3, 1)\n",
    "        \n",
    "        \n",
    "        print(\"slow_frames shape:\", slow_frames.shape)\n",
    "        print(\"fast_frames shape:\", fast_frames.shape)\n",
    "\n",
    "        pred = model_binary(slow_frames, fast_frames)\n",
    "        loss = loss_function(pred.squeeze(), labels.float())\n",
    "\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        torch.cuda.empty_cache()  \n",
    "    # Store training loss\n",
    "    losses[0, epoch] = epoch_loss / len(training_dataloader)\n",
    "\n",
    "    # Validation Loop\n",
    "    model_binary.eval()\n",
    "    test_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_frames, test_labels in tqdm(testing_dataloader, desc=\"Cycling Testing Dataloader\"):\n",
    "            slow_test_frames, fast_test_frames = test_frames  # Unpack test data\n",
    "            \n",
    "            slow_test_frames, fast_test_frames, test_labels = (\n",
    "                slow_test_frames.to(device),\n",
    "                fast_test_frames.to(device),\n",
    "                test_labels.to(device),\n",
    "            )\n",
    "            slow_test_frames = slow_test_frames.permute(0, 4, 2, 3, 1)\n",
    "            fast_test_frames = fast_test_frames.permute(0, 4, 2, 3, 1)\n",
    "\n",
    "            test_preds = model_binary(slow_test_frames, fast_test_frames)  \n",
    "            t_loss = loss_function(test_preds.squeeze(), test_labels.float())\n",
    "\n",
    "            test_loss += t_loss.item()\n",
    "            \n",
    "    losses[1, epoch] = test_loss / len(testing_dataloader)\n",
    "\n",
    "    # Save best model\n",
    "    if best_loss > losses[1, epoch]:\n",
    "        best_loss = losses[1, epoch] \n",
    "        print(f\"Saving Optimal model: {epoch + 1} epoch\")\n",
    "        torch.save(model_binary.state_dict(), os.path.join(\"Best_Models\", \"E2E_SF.pt\"))\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] - Training Loss: {losses[0,epoch]:.4f}, Test Loss: {losses[1,epoch]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf572668-0cb3-4eaf-8d28-189be1aeb668",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses[0], label = 'Training')\n",
    "plt.plot(losses[1], label = 'Testing')\n",
    "plt.grid()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Slow-Fast Binary Classification Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1319a8-cb86-4a0a-ad58-00268bfca9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_binary.load_state_dict(torch.load(os.path.join(\"Best_Models\", \"E2E_SF.pt\")))\n",
    "print(\"Best model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13190fd4-0354-47dd-9f38-46f95fe77e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, dataloader, device):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation for efficiency\n",
    "        for frames, labels in dataloader:\n",
    "            frames = frames.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(frames)  # Forward pass\n",
    "           # _, preds = torch.max(outputs, 1)  # Get predicted class MULTICLASS APPROACH\n",
    "            #preds = (outputs >= 0.5).float() # Binalry class \n",
    "            preds = (torch.sigmoid(outputs) >= 0.5).float()\n",
    "            all_preds.extend(preds.cpu().numpy())  # Store predictions\n",
    "            all_labels.extend(labels.cpu().numpy())  # Store true labels\n",
    "\n",
    "    return np.array(all_labels), np.array(all_preds)\n",
    "\n",
    "# Example usage:\n",
    "device = torch.device(device)  # Change to \"cuda\" if using GPU\n",
    "true_labels, pred_labels = get_predictions(model_binary, testing_dataloader, device)\n",
    "print(f\"Total test samples: {len(true_labels)} (Expected: 29270)\")\n",
    "print(f\"Total predictions: {len(pred_labels)} (Expected: 29270)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439542b5-3f22-4351-a06e-46cc22fa0f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(true_labels, pred_labels)\n",
    "sns.heatmap(cm , annot = True)\n",
    "plt.title(\"Confusion Matrix of Slow-Fast Classifier\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8e694c-afc7-4c31-955a-a60f06c9f7d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
