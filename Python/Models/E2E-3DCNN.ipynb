{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24aa918b-9785-436a-9346-178740c3cba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# END2END RESNET \n",
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0889fc5c-1ed1-4f0c-90ec-3acc1f670fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_INTERVAL = 5  # Capture every 5th frame\n",
    "CLIP_LENGTH = 16  # Number of frames per clip for 3D CNN\n",
    "FRAME_HEIGHT, FRAME_WIDTH = 112, 112  # r3d_18 with input 112x112"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37220eab-22a6-479d-800b-844802d73919",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_DIR = r\"C:\\Users\\Keelan.Butler\\Desktop\\python_projects\\Final Project\\OneDrive_2025-01-30\\MSAD Dataset\\MSAD_blur\"\n",
    "SAVE_DIR = r\"C:\\Users\\Keelan.Butler\\Desktop\\python_projects\\Final Project\\Processed_Frames\"\n",
    "Anomaly_dir = r\"C:\\Users\\Keelan.Butler\\Desktop\\python_projects\\Final Project\\OneDrive_2025-01-30\\MSAD Dataset\\anomaly_annotation.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75b4f4bb-8d85-4ce7-ae42-7b76709af172",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((FRAME_HEIGHT, FRAME_WIDTH)), \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalising the features\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d215b6d6-0fba-4b17-b500-17c3ed7905eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomalies: {'People', 'Object', 'Shooting', 'Vandalism', 'Water', 'Explosion', 'Robbery', 'Traffic', 'Assault', 'Fighting', 'Fire'}\n"
     ]
    }
   ],
   "source": [
    "Anomaly_data = pd.read_csv(Anomaly_dir)\n",
    "anomalies = set([anon.split(\"_\")[0] for anon in Anomaly_data.name.values])\n",
    "print(f'Anomalies: {anomalies}')\n",
    "\n",
    "anno_names = Anomaly_data.name.values.tolist()\n",
    "anno_start = Anomaly_data['starting frame of anomaly'].values.tolist()\n",
    "anno_end = Anomaly_data['ending frame of anomaly'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c055e9cb-3ddd-4944-a9a2-c10c339ce363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save directory for extracted frames\n",
    "\n",
    "def extract_and_save_frames(video_path, save_dir, frame_interval=5):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    save_folder = os.path.join(save_dir, video_name)\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "    frame_count = 0\n",
    "    saved_count = 0\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break  # End of video\n",
    "\n",
    "        if frame_count % frame_interval == 0:\n",
    "            # Convert BGR (OpenCV) to RGB (PIL)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Apply transformations\n",
    "            frame = transform(frame)  # Now it's a Tensor (C, H, W)\n",
    "\n",
    "            # Convert back to PIL image to save\n",
    "            frame = transforms.ToPILImage()(frame)\n",
    "\n",
    "            # Save frame as JPEG\n",
    "            frame_path = os.path.join(save_folder, f\"frame_{saved_count:04d}.jpg\")\n",
    "            frame.save(frame_path, \"JPEG\")\n",
    "            saved_count += 1 \n",
    "\n",
    "        frame_count += 1\n",
    "    \n",
    "    cap.release()\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7918ee46-93a8-4f43-a866-6c9d4595d014",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Frames: 0it [00:00, ?it/s]\n",
      "Extracting Frames: 0it [00:00, ?it/s]\n",
      "Extracting Frames: 100%|██████████████████████████████████████████████████████████████████████████████████████| 15/15 [02:16<00:00,  9.13s/it]\n",
      "Extracting Frames: 100%|██████████████████████████████████████████████████████████████████████████████████████| 15/15 [01:22<00:00,  5.47s/it]\n",
      "Extracting Frames: 100%|██████████████████████████████████████████████████████████████████████████████████████| 13/13 [02:32<00:00, 11.69s/it]\n",
      "Extracting Frames: 100%|██████████████████████████████████████████████████████████████████████████████████████| 25/25 [05:13<00:00, 12.52s/it]\n",
      "Extracting Frames: 100%|██████████████████████████████████████████████████████████████████████████████████████| 22/22 [02:31<00:00,  6.87s/it]\n",
      "Extracting Frames: 100%|██████████████████████████████████████████████████████████████████████████████████████| 43/43 [03:07<00:00,  4.36s/it]\n",
      "Extracting Frames: 100%|██████████████████████████████████████████████████████████████████████████████████████| 29/29 [04:04<00:00,  8.42s/it]\n",
      "Extracting Frames: 100%|██████████████████████████████████████████████████████████████████████████████████████| 17/17 [01:39<00:00,  5.88s/it]\n",
      "Extracting Frames: 100%|██████████████████████████████████████████████████████████████████████████████████████| 39/39 [03:33<00:00,  5.47s/it]\n",
      "Extracting Frames: 100%|██████████████████████████████████████████████████████████████████████████████████████| 12/12 [01:54<00:00,  9.52s/it]\n",
      "Extracting Frames: 100%|██████████████████████████████████████████████████████████████████████████████████████| 10/10 [01:30<00:00,  9.07s/it]\n",
      "Extracting Frames: 100%|████████████████████████████████████████████████████████████████████████████████████| 120/120 [32:38<00:00, 16.32s/it]\n",
      "Extracting Frames: 0it [00:00, ?it/s]\n",
      "Extracting Frames: 100%|█████████████████████████████████████████████████████████████████████████████████| 27/27 [11:44:41<00:00, 1565.98s/it]\n",
      "Extracting Frames: 100%|██████████████████████████████████████████████████████████████████████████████████████| 25/25 [02:53<00:00,  6.94s/it]\n",
      "Extracting Frames: 100%|██████████████████████████████████████████████████████████████████████████████████████| 30/30 [03:56<00:00,  7.87s/it]\n",
      "Extracting Frames: 100%|██████████████████████████████████████████████████████████████████████████████████████| 15/15 [03:05<00:00, 12.35s/it]\n",
      "Extracting Frames: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [04:35<00:00, 11.47s/it]\n",
      "Extracting Frames: 100%|██████████████████████████████████████████████████████████████████████████████████████| 27/27 [05:07<00:00, 11.40s/it]\n",
      "Extracting Frames: 100%|██████████████████████████████████████████████████████████████████████████████████████| 29/29 [05:33<00:00, 11.49s/it]\n",
      "Extracting Frames: 100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [04:02<00:00, 11.52s/it]\n",
      "Extracting Frames: 100%|██████████████████████████████████████████████████████████████████████████████████████| 35/35 [07:18<00:00, 12.52s/it]\n",
      "Extracting Frames: 100%|██████████████████████████████████████████████████████████████████████████████████████| 26/26 [03:03<00:00,  7.07s/it]\n",
      "Extracting Frames: 100%|██████████████████████████████████████████████████████████████████████████████████████| 27/27 [03:35<00:00,  7.98s/it]\n",
      "Extracting Frames: 100%|██████████████████████████████████████████████████████████████████████████████████████| 26/26 [03:55<00:00,  9.06s/it]\n",
      "Extracting Frames: 100%|██████████████████████████████████████████████████████████████████████████████████████| 25/25 [03:17<00:00,  7.91s/it]\n",
      "Extracting Frames: 100%|██████████████████████████████████████████████████████████████████████████████████████| 23/23 [02:46<00:00,  7.24s/it]\n"
     ]
    }
   ],
   "source": [
    "for root, _, files in os.walk(VIDEO_DIR):\n",
    "    for video_file in tqdm(files, desc=f\"Extracting Frames {root}\"):\n",
    "        if video_file.endswith((\".mp4\", \".avi\", \".mov\")):\n",
    "            video_path = os.path.join(root, video_file)\n",
    "            anon_label = extract_and_save_frames(video_path, SAVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4e6c59f0-4a89-4970-9f06-b70ff3837e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly = []\n",
    "anonamly_bool = []\n",
    "frame_paths = []\n",
    "frames = []\n",
    "video_names = []\n",
    "video_path = []\n",
    "import os\n",
    "for root, _, files in os.walk(SAVE_DIR):\n",
    "   for name in files:\n",
    "      frame_path = os.path.join(root, name)\n",
    "      components = frame_path.split(os.sep) \n",
    "      video_name =  components[-2]\n",
    "      frame = int(components[-1].split(\"_\")[1].split(\".\")[0]) * FRAME_INTERVAL\n",
    "      frames.append(frame)\n",
    "      video_names.append(video_name)\n",
    "      #print(video_name) \n",
    "      frame_paths.append(frame_path)\n",
    "      anom = video_name.split(\"_\")[0]\n",
    "      if anom in anomalies:\n",
    "          #print(frame,video_name)\n",
    "          pos = anno_names.index(video_name)\n",
    "          start = anno_start[pos]\n",
    "          end = anno_end[pos]\n",
    "\n",
    "          if start < frame < end: \n",
    "              anon_bool = 1 \n",
    "              anomaly_label = anom\n",
    "          else:\n",
    "              anon_bool = 0\n",
    "              anomaly_label = \"Normal\"\n",
    "         \n",
    "      else:\n",
    "          anon_bool = 0\n",
    "          anomaly_label = \"Normal\"\n",
    "      anomaly.append(anomaly_label)\n",
    "      anonamly_bool.append(anon_bool)\n",
    "\n",
    "\n",
    "metadata = pd.DataFrame({'Video':video_names,\n",
    "              'Frame':frames,\n",
    "             'Frames_path':frame_paths, \n",
    "             \"Anomaly Type\": anomaly,\n",
    "             \"Anomaly\": anonamly_bool})\n",
    "\n",
    "metadata[\"Video\"] = metadata[\"Video\"].str.replace(\"MSAD_normal_\", \"\", regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0a77195a-7b93-4dac-8c93-2b895e873e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video</th>\n",
       "      <th>Frame</th>\n",
       "      <th>Frames_path</th>\n",
       "      <th>Anomaly Type</th>\n",
       "      <th>Anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Assault_1</td>\n",
       "      <td>0</td>\n",
       "      <td>C:\\Users\\Keelan.Butler\\Desktop\\python_projects...</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Assault_1</td>\n",
       "      <td>5</td>\n",
       "      <td>C:\\Users\\Keelan.Butler\\Desktop\\python_projects...</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Assault_1</td>\n",
       "      <td>10</td>\n",
       "      <td>C:\\Users\\Keelan.Butler\\Desktop\\python_projects...</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Assault_1</td>\n",
       "      <td>15</td>\n",
       "      <td>C:\\Users\\Keelan.Butler\\Desktop\\python_projects...</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Assault_1</td>\n",
       "      <td>20</td>\n",
       "      <td>C:\\Users\\Keelan.Butler\\Desktop\\python_projects...</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89666</th>\n",
       "      <td>Water_incident_9</td>\n",
       "      <td>405</td>\n",
       "      <td>C:\\Users\\Keelan.Butler\\Desktop\\python_projects...</td>\n",
       "      <td>Water</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89667</th>\n",
       "      <td>Water_incident_9</td>\n",
       "      <td>410</td>\n",
       "      <td>C:\\Users\\Keelan.Butler\\Desktop\\python_projects...</td>\n",
       "      <td>Water</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89668</th>\n",
       "      <td>Water_incident_9</td>\n",
       "      <td>415</td>\n",
       "      <td>C:\\Users\\Keelan.Butler\\Desktop\\python_projects...</td>\n",
       "      <td>Water</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89669</th>\n",
       "      <td>Water_incident_9</td>\n",
       "      <td>420</td>\n",
       "      <td>C:\\Users\\Keelan.Butler\\Desktop\\python_projects...</td>\n",
       "      <td>Water</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89670</th>\n",
       "      <td>Water_incident_9</td>\n",
       "      <td>425</td>\n",
       "      <td>C:\\Users\\Keelan.Butler\\Desktop\\python_projects...</td>\n",
       "      <td>Water</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89671 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Video  Frame  \\\n",
       "0             Assault_1      0   \n",
       "1             Assault_1      5   \n",
       "2             Assault_1     10   \n",
       "3             Assault_1     15   \n",
       "4             Assault_1     20   \n",
       "...                 ...    ...   \n",
       "89666  Water_incident_9    405   \n",
       "89667  Water_incident_9    410   \n",
       "89668  Water_incident_9    415   \n",
       "89669  Water_incident_9    420   \n",
       "89670  Water_incident_9    425   \n",
       "\n",
       "                                             Frames_path Anomaly Type  Anomaly  \n",
       "0      C:\\Users\\Keelan.Butler\\Desktop\\python_projects...       Normal        0  \n",
       "1      C:\\Users\\Keelan.Butler\\Desktop\\python_projects...       Normal        0  \n",
       "2      C:\\Users\\Keelan.Butler\\Desktop\\python_projects...       Normal        0  \n",
       "3      C:\\Users\\Keelan.Butler\\Desktop\\python_projects...       Normal        0  \n",
       "4      C:\\Users\\Keelan.Butler\\Desktop\\python_projects...       Normal        0  \n",
       "...                                                  ...          ...      ...  \n",
       "89666  C:\\Users\\Keelan.Butler\\Desktop\\python_projects...        Water        1  \n",
       "89667  C:\\Users\\Keelan.Butler\\Desktop\\python_projects...        Water        1  \n",
       "89668  C:\\Users\\Keelan.Butler\\Desktop\\python_projects...        Water        1  \n",
       "89669  C:\\Users\\Keelan.Butler\\Desktop\\python_projects...        Water        1  \n",
       "89670  C:\\Users\\Keelan.Butler\\Desktop\\python_projects...        Water        1  \n",
       "\n",
       "[89671 rows x 5 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "18baf978-0689-4d25-ae34-52256684cf27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video</th>\n",
       "      <th>partition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Assault_1</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Assault_3</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Assault_5</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Assault_6</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Assault_9</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>testing_116</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>testing_117</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>testing_118</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>testing_119</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>testing_120</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>720 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Video partition\n",
       "0      Assault_1     Train\n",
       "1      Assault_3     Train\n",
       "2      Assault_5     Train\n",
       "3      Assault_6     Train\n",
       "4      Assault_9     Train\n",
       "..           ...       ...\n",
       "235  testing_116      Test\n",
       "236  testing_117      Test\n",
       "237  testing_118      Test\n",
       "238  testing_119      Test\n",
       "239  testing_120      Test\n",
       "\n",
       "[720 rows x 2 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(r'C:\\Users\\Keelan.Butler\\Desktop\\python_projects\\Final Project\\OneDrive_2025-01-30\\MSAD Dataset\\MSAD_I3D_WS_Train.list') as train:\n",
    "    t = train.readlines()\n",
    "    train_list = [item.split(\"\\n\")[0].split(\"/\")[-1].replace(\"_i3d.npy\",\"\") for item in t]\n",
    "    train_label = [\"Train\"] * len(train_list)\n",
    "tr_labels = pd.DataFrame({\"Video\":train_list,\n",
    "                        \"partition\":train_label}) \n",
    "with open(r'C:\\Users\\Keelan.Butler\\Desktop\\python_projects\\Final Project\\OneDrive_2025-01-30\\MSAD Dataset\\MSAD_I3D_WS_Test.list') as test:\n",
    "    t = test.readlines()\n",
    "    test_list = [item.split(\"\\n\")[0].split(\"/\")[-1].replace(\"_i3d.npy\",\"\") for item in t]\n",
    "    test_label = [\"Test\"] * len(test_list)\n",
    "\n",
    "te_labels = pd.DataFrame({\"Video\":test_list,\n",
    "                         \"partition\":test_label})\n",
    "label_df = pd.concat([tr_labels,te_labels])\n",
    "label_df[\"Video\"] = label_df[\"Video\"].str.replace(\"MSAD_normal_\", \"\", regex=False)\n",
    "label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b3e16f7e-bd3e-4ac5-a74f-7e871eb1f3ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partition</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Video\n",
       "partition       \n",
       "Test         240\n",
       "Train        480"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df.groupby(\"partition\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "66290c63-c6bf-4890-8af0-c343ba1170c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(left= metadata, right = label_df , on= \"Video\",how= \"left\")\n",
    "df_train =  df[df[\"partition\"] == \"Train\"].drop(columns= \"partition\")\n",
    "df_test =  df[df[\"partition\"] == \"Test\"].drop(columns= \"partition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8375e646-5a7a-495e-9eb3-1ce828fa3b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrameDataset(Dataset):\n",
    "    def __init__(self, labels_df, transform=None, clip_length=16, step_size=8):\n",
    "        \"\"\"\n",
    "        labels_df: DataFrame with columns [\"Video\", \"Frame\", \"Frames_path\", \"Anomaly Type\", \"Anomaly\"]\n",
    "        transform: Image transformations (for resizing, normalizing, etc.)\n",
    "        clip_length: Number of frames per sample (default 16 for ResNet3D)\n",
    "        step_size: How far the window moves per sample (default 8 frames)\n",
    "        \"\"\"\n",
    "        self.labels_df = labels_df\n",
    "        self.transform = transform\n",
    "        self.clip_length = clip_length\n",
    "        self.step_size = step_size  # New parameter\n",
    "\n",
    "        # Ensure data is sorted by video and frame number\n",
    "        self.labels_df.sort_values(by=[\"Video\", \"Frame\"], inplace=True)\n",
    "\n",
    "        # Group frames by video\n",
    "        self.video_groups = self.labels_df.groupby(\"Video\")\n",
    "\n",
    "        # Prepare label encoder for anomaly labels\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.labels_df[\"Encoded_Label\"] = self.label_encoder.fit_transform(self.labels_df[\"Anomaly\"])\n",
    "\n",
    "        # Store unique videos\n",
    "        self.video_list = list(self.video_groups.groups.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_list)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        # Select a video\n",
    "        video_name = self.video_list[idx]\n",
    "        video_frames = self.video_groups.get_group(video_name)\n",
    "    \n",
    "        # Ensure frames are in order\n",
    "        frame_paths = video_frames[\"Frames_path\"].tolist()\n",
    "        frame_labels = video_frames[\"Encoded_Label\"].tolist()\n",
    "    \n",
    "        # Sliding window start index\n",
    "        start_idx = (idx * self.step_size) % max(1, len(frame_paths) - self.clip_length)\n",
    "    \n",
    "        selected_frames = frame_paths[start_idx:start_idx + self.clip_length]\n",
    "        selected_labels = frame_labels[start_idx:start_idx + self.clip_length]\n",
    "        while len(selected_frames) < self.clip_length:\n",
    "            selected_frames.append(selected_frames[-1])  # Repeat last frame\n",
    "\n",
    "        while len(selected_labels) < self.clip_length:\n",
    "            selected_labels.append(selected_labels[-1])  # Repeat last label\n",
    "        # Load and transform frames\n",
    "        frames = []\n",
    "        for frame_path in selected_frames:\n",
    "            frame = cv2.imread(frame_path)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "            if self.transform:\n",
    "                frame = self.transform(frame)\n",
    "            else:\n",
    "                frame = torch.from_numpy(frame).float()  \n",
    "    \n",
    "            frames.append(frame)  \n",
    "    \n",
    "        frames = torch.stack(frames)  # Shape: (16, 3, 112, 112)\n",
    "    \n",
    "        # Ensure correct shape for Conv3D: (3, 16, 112, 112)\n",
    "        #frames = frames.permute(1, 0, 2, 3)  # (3, 16, 112, 112)\n",
    "    \n",
    "        # Assign majority label\n",
    "        clip_label = 1 if sum(selected_labels) > self.clip_length // 2 else 0\n",
    "\n",
    "        return frames.permute(3,0,1,2), torch.tensor(clip_label, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b7c47c54-7adc-4b81-96b5-e0a168ef68cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 454\n",
      "testing dataset size: 240\n"
     ]
    }
   ],
   "source": [
    "training_dataset = FrameDataset(labels_df=df_train)\n",
    "testing_dataset = FrameDataset(labels_df=df_test)\n",
    "print(\"Training dataset size: {}\\ntesting dataset size: {}\".format(len(training_dataset),len(testing_dataset)))\n",
    "training_dataloader = torch.utils.data.DataLoader(training_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "testing_dataloader = torch.utils.data.DataLoader(testing_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ca15aa48-f413-4d5e-80db-3507224aeb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total anomalies in dataloader: 69/454 (15.20%)\n"
     ]
    }
   ],
   "source": [
    "total_anomalies = 0\n",
    "total_samples = 0\n",
    "\n",
    "for _, labels in training_dataloader:\n",
    "    total_anomalies += torch.sum(labels).item()\n",
    "    total_samples += len(labels)\n",
    "\n",
    "print(f\"Total anomalies in dataloader: {total_anomalies}/{total_samples} ({(total_anomalies/total_samples)*100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b96b748b-1347-43d9-8a0c-aae781ef8cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total anomalies in dataloader: 79/240 (32.92%)\n"
     ]
    }
   ],
   "source": [
    "total_anomalies = 0\n",
    "total_samples = 0\n",
    "\n",
    "for _, labels in testing_dataloader:\n",
    "    total_anomalies += torch.sum(labels).item()\n",
    "    total_samples += len(labels)\n",
    "\n",
    "print(f\"Total anomalies in dataloader: {total_anomalies}/{total_samples} ({(total_anomalies/total_samples)*100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fdc867c3-7cca-4015-af9c-a48cbbb7261e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Keelan.Butler\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Keelan.Butler\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=R3D_18_Weights.KINETICS400_V1`. You can also use `weights=R3D_18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model_binary = models.video.r3d_18(pretrained=True)\n",
    "model_binary = nn.Sequential(*list(model_binary.children())[:-1], \n",
    "             nn.Flatten(),\n",
    "             nn.Linear(512,256),\n",
    "             nn.Dropout(0.5),\n",
    "             nn.Linear(256,1),\n",
    "             nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5c472a1d-079e-48df-a977-35a7a1e191d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftF1Loss(torch.nn.Module):\n",
    "    def __init__(self, epsilon=1e-7):\n",
    "        super(SoftF1Loss, self).__init__()\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        \"\"\"\n",
    "        y_pred: Model outputs (logits or probabilities after sigmoid)\n",
    "        y_true: Ground truth labels (binary: 0 or 1)\n",
    "        \"\"\"\n",
    "        y_pred = torch.sigmoid(y_pred)  # Ensure predictions are between 0 and 1\n",
    "        \n",
    "        tp = torch.sum(y_true * y_pred)  # True Positives\n",
    "        fp = torch.sum((1 - y_true) * y_pred)  # False Positives\n",
    "        fn = torch.sum(y_true * (1 - y_pred))  # False Negatives\n",
    "\n",
    "        f1 = (2 * tp + self.epsilon) / (2 * tp + fp + fn + self.epsilon)\n",
    "        return 1 - f1  # Minimize (1 - F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684b2d22-00f3-4bd3-9eb5-9dd43b7fa982",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Saving Optimal model: 0 epoch\n",
      "Epoch [1/50] - Training Loss: 0.4827, Test Loss: 22.8062\n",
      "Saving Optimal model: 1 epoch\n",
      "Epoch [2/50] - Training Loss: 0.4079, Test Loss: 3.8928\n",
      "Saving Optimal model: 2 epoch\n",
      "Epoch [3/50] - Training Loss: 0.4097, Test Loss: 1.7137\n",
      "Saving Optimal model: 3 epoch\n",
      "Epoch [4/50] - Training Loss: 0.3331, Test Loss: 0.8182\n",
      "Saving Optimal model: 4 epoch\n",
      "Epoch [5/50] - Training Loss: 0.3915, Test Loss: 0.6641\n",
      "Epoch [6/50] - Training Loss: 0.2405, Test Loss: 1.5449\n",
      "Epoch [7/50] - Training Loss: 0.3227, Test Loss: 1.4135\n",
      "Epoch [8/50] - Training Loss: 0.2614, Test Loss: 0.7457\n",
      "Epoch [9/50] - Training Loss: 0.1562, Test Loss: 1.1330\n",
      "Epoch [10/50] - Training Loss: 0.1103, Test Loss: 0.9574\n",
      "Epoch [11/50] - Training Loss: 0.0800, Test Loss: 1.1873\n"
     ]
    }
   ],
   "source": [
    "# Training Hyperparameters\n",
    "epochs = 50\n",
    "losses = np.zeros((2, epochs))\n",
    "optimizer = optim.Adam(model_binary.parameters(), lr=0.001)\n",
    "loss_function = nn.BCELoss()  # Binary Cross Entropy Loss\n",
    "#loss_function = SoftF1Loss()\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model_binary.to(device)\n",
    "best_loss = np.inf\n",
    "\n",
    "\n",
    "threshhold = 0.5 \n",
    "# Training Loop\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0.0\n",
    "    model_binary.train()\n",
    "\n",
    "    for frames, labels in training_dataloader:\n",
    "        frames, labels = frames.to(device), labels.to(device)  # Move data to GPU if available\n",
    "\n",
    "        pred = model_binary(frames)  # Forward pass\n",
    "        loss = loss_function(pred.view(-1), labels.float())  # Ensure label is float for BCELoss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    # Store training loss\n",
    "    losses[0, epoch] = epoch_loss / len(training_dataloader)\n",
    "\n",
    "    # Validation Loop\n",
    "    model_binary.eval()\n",
    "    test_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_frames, test_labels in testing_dataloader:\n",
    "            test_frames, test_labels = test_frames.to(device), test_labels.to(device)  # Move to GPU\n",
    "\n",
    "            test_preds = model_binary(test_frames)\n",
    "            loss = loss_function(test_preds.view(-1), test_labels.float())\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "    losses[1, epoch] = test_loss / len(testing_dataloader)\n",
    "    if best_loss > losses[1, epoch]:\n",
    "        best_loss = losses[1, epoch] \n",
    "        print(\"Saving Optimal model: {} epoch\".format(epoch + 1))\n",
    "        torch.save(model_binary.state_dict(),os.path.join(\"Best_Models\",\"E2E_3DCNN.pt\"))\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] - Training Loss: {losses[0,epoch]:.4f}, Test Loss: {losses[1,epoch]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ce6961-562e-4ff3-bbce-327583213478",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses[0], label = 'Training')\n",
    "plt.plot(losses[1], label = 'Testing')\n",
    "plt.grid()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"R3D CNN Training Binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87719967-469f-423b-9cbb-1ae6efa5d693",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_binary = model_binary.load_state_dict(torch.load(os.path.join(\"Best_Models\",\"E2E_3DCNN.pt\")))\n",
    "print(\"Best model loaded!\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53820b2-bcdd-496a-b73e-2d0801af1fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, dataloader, device):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation for efficiency\n",
    "        for frames, labels in dataloader:\n",
    "            frames = frames.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(frames)  # Forward pass\n",
    "            _, preds = torch.max(outputs, 1)  # Get predicted class\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())  # Store predictions\n",
    "            all_labels.extend(labels.cpu().numpy())  # Store true labels\n",
    "\n",
    "    return np.array(all_labels), np.array(all_preds)\n",
    "\n",
    "# Example usage:\n",
    "device = torch.device(\"cpu\")  # Change to \"cuda\" if using GPU\n",
    "true_labels, pred_labels = get_predictions(model_binary, testing_dataloader, device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27708ba0-019b-4e20-a9c3-bd5874fbc5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(true_labels, pred_labels)\n",
    "sns.heatmap(cm , annot = True)\n",
    "plt.title(\"Confusion Matrix of 3D ResNet-18 Classifier\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db00be35-2853-40f2-846c-cd9e6882f864",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
